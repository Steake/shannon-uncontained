# Shannon Uncontained - Environment Variables
# Copy this file to .env and fill in the values

# =============================================================================
# LLM PROVIDER CONFIGURATION
# =============================================================================
# Shannon supports multiple LLM providers. Configure ONE of the following:

# Option 1: GitHub Models (Recommended for free tier)
# Get your token from: https://github.com/settings/tokens
# No special scopes required for GitHub Models
GITHUB_TOKEN=

# Option 2: OpenAI API
# Get your key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=

# Option 3: Anthropic Claude
# Get your key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=

# =============================================================================
# PROVIDER SELECTION (Optional)
# =============================================================================
# If multiple keys are set, specify which provider to use:
# Options: github, openai, anthropic
# Default: auto-detect based on which key is set
# LLM_PROVIDER=github

# =============================================================================
# MODEL SELECTION (Optional)
# =============================================================================
# Override the default model for your provider:
# GitHub Models: openai/gpt-4.1, openai/gpt-4o, meta-llama-3.1-405b-instruct
# OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# LLM_MODEL=

# =============================================================================
# OPTIONAL SETTINGS
# =============================================================================
# Max output tokens (for long reports)
# CLAUDE_CODE_MAX_OUTPUT_TOKENS=64000
